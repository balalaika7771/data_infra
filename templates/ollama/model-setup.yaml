{{- if .Values.ollama.enabled }}
---
# Job для загрузки модели по умолчанию при первом запуске
apiVersion: batch/v1
kind: Job
metadata:
  name: ollama-model-setup-{{ .Values.ollama.defaultModel | replace ":" "-" | replace "." "-" }}
  namespace: {{ .Values.ollama.namespace }}
  annotations:
    argocd.argoproj.io/sync-options: Prune=false
    argocd.argoproj.io/sync-wave: "2"
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: model-setup
        image: curlimages/curl:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "Ожидание запуска Ollama..."
          # Ждем до 5 минут пока Ollama не будет готов
          for i in {1..30}; do
            if curl -f -s http://ollama.{{ .Values.ollama.namespace }}.svc.cluster.local:11434/api/tags > /dev/null; then
              echo "Ollama готов!"
              break
            fi
            echo "Ollama еще не готов, ждем... ($i/30)"
            sleep 10
          done
          
          # Проверяем готовность еще раз
          if ! curl -f -s http://ollama.{{ .Values.ollama.namespace }}.svc.cluster.local:11434/api/tags > /dev/null; then
            echo "ОШИБКА: Ollama не готов после 5 минут ожидания"
            exit 1
          fi
          
          echo "Проверяем, загружена ли модель {{ .Values.ollama.defaultModel }}..."
          MODELS_RESPONSE=$(curl -s http://ollama.{{ .Values.ollama.namespace }}.svc.cluster.local:11434/api/tags)
          echo "Ответ от API: $MODELS_RESPONSE"
          
          if echo "$MODELS_RESPONSE" | grep -q "{{ .Values.ollama.defaultModel }}"; then
            echo "Модель {{ .Values.ollama.defaultModel }} уже загружена."
          else
            echo "Загружаем модель {{ .Values.ollama.defaultModel }}..."
            curl -X POST http://ollama.{{ .Values.ollama.namespace }}.svc.cluster.local:11434/api/pull \
              -H "Content-Type: application/json" \
              -d '{"name": "{{ .Values.ollama.defaultModel }}"}'
            echo "Модель {{ .Values.ollama.defaultModel }} загружена успешно!"
          fi
          
          echo "Финальная проверка - доступные модели:"
          curl -s http://ollama.{{ .Values.ollama.namespace }}.svc.cluster.local:11434/api/tags
          echo ""
          echo "✅ Инициализация Ollama завершена успешно!"
  backoffLimit: 3
{{- end }}
